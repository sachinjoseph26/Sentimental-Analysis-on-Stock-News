{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pull News about each Stock*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Get today's date\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Define the start and end dates\n",
    "#start_date = datetime(2021, 1, 1)\n",
    "#end_date = datetime(2024, 4, 10)\n",
    "\n",
    "with open('news_data.csv', 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['Stock Name','Date','Time','News Headline'])\n",
    "\n",
    "stocks = ['TSLA','AMD','NVDA','MU','PLTR','NIO','AAPL','MARA','WBA','CLSK','F','CCL','SOFI','T','BAC','GOOGL','VALE','GOLD','INTC','AMZN']\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "\n",
    "for stock in stocks:\n",
    "    final_url = finviz_url + stock\n",
    "    request = Request(url=final_url, headers={'user-agent': 'app'}) \n",
    "    response = urlopen(request)    \n",
    "    html = BeautifulSoup(response, features=\"lxml\")\n",
    "    news_table = html.find('table',id='news-table')\n",
    "    news_table_row = news_table.find_all('tr')\n",
    "    for news in news_table_row:\n",
    "        news_headline = news.a.get_text() \n",
    "        date_scrape = news.td.text.split()\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            # Replace \"Today\" with today's date\n",
    "            news_date = today_date\n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "            # Replace \"Today\" with today's date\n",
    "            if date.lower() == \"today\":\n",
    "                news_date = today_date\n",
    "            else:\n",
    "                # Convert the scraped date to a datetime object\n",
    "                news_date = datetime.strptime(date, '%b-%d-%y').date()  # Extracting only the date portion\n",
    "            # Check if the news date falls within the specified range\n",
    "            \n",
    "            with open('news_data.csv', 'a', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([stock, news_date, time, news_headline])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Annotate sentiments of news headlines with a pretrained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>10:03AM</td>\n",
       "      <td>Tesla settles lawsuit in fatal crash where dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>10:08PM</td>\n",
       "      <td>Tesla wants Apple's help proving a driver was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>08:42PM</td>\n",
       "      <td>Wall Street Analysts Just Trimmed Price Target...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>09:51AM</td>\n",
       "      <td>How's AT&amp;T Handling Things?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst unveils new Amazon price target as sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>06:46PM</td>\n",
       "      <td>Here Are My 3 Top Tech Stocks to Buy Right Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Best Stock to Buy Right Now: Amazon vs. Disney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>07:22PM</td>\n",
       "      <td>Amazon continues construction on Puget Sound t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>10:11PM</td>\n",
       "      <td>20 Most Buddhist Countries in Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name        Date     Time  \\\n",
       "0         TSLA  2024-04-09  10:03AM   \n",
       "1         TSLA  2024-04-08  10:46PM   \n",
       "2         TSLA  2024-04-07  10:08PM   \n",
       "3         TSLA  2024-04-06  08:42PM   \n",
       "4          AMD  2024-04-09  09:51AM   \n",
       "..         ...         ...      ...   \n",
       "562       AMZN  2024-04-08  07:03PM   \n",
       "563       AMZN  2024-04-07  06:46PM   \n",
       "564       AMZN  2024-04-06  10:00AM   \n",
       "565       AMZN  2024-04-05  07:22PM   \n",
       "566       AMZN  2024-04-04  10:11PM   \n",
       "\n",
       "                                         News Headline  \n",
       "0    Tesla settles lawsuit in fatal crash where dri...  \n",
       "1    Tesla Agrees to Settle Lawsuit Over Autopilots...  \n",
       "2    Tesla wants Apple's help proving a driver was ...  \n",
       "3    Wall Street Analysts Just Trimmed Price Target...  \n",
       "4                          How's AT&T Handling Things?  \n",
       "..                                                 ...  \n",
       "562  Analyst unveils new Amazon price target as sto...  \n",
       "563     Here Are My 3 Top Tech Stocks to Buy Right Now  \n",
       "564     Best Stock to Buy Right Now: Amazon vs. Disney  \n",
       "565  Amazon continues construction on Puget Sound t...  \n",
       "566                 20 Most Buddhist Countries in Asia  \n",
       "\n",
       "[567 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('news_data.csv',encoding='ISO-8859-1')\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=finbert, tokenizer=tokenizer)\n",
    "\n",
    "df_news['Sentiment'] = df_news['News Headline'].apply(lambda x: nlp(x)[0]['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>10:03AM</td>\n",
       "      <td>Tesla settles lawsuit in fatal crash where dri...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>10:08PM</td>\n",
       "      <td>Tesla wants Apple's help proving a driver was ...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>08:42PM</td>\n",
       "      <td>Wall Street Analysts Just Trimmed Price Target...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>09:51AM</td>\n",
       "      <td>How's AT&amp;T Handling Things?</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst unveils new Amazon price target as sto...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>06:46PM</td>\n",
       "      <td>Here Are My 3 Top Tech Stocks to Buy Right Now</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Best Stock to Buy Right Now: Amazon vs. Disney</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>07:22PM</td>\n",
       "      <td>Amazon continues construction on Puget Sound t...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-04</td>\n",
       "      <td>10:11PM</td>\n",
       "      <td>20 Most Buddhist Countries in Asia</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name        Date     Time  \\\n",
       "0         TSLA  2024-04-09  10:03AM   \n",
       "1         TSLA  2024-04-08  10:46PM   \n",
       "2         TSLA  2024-04-07  10:08PM   \n",
       "3         TSLA  2024-04-06  08:42PM   \n",
       "4          AMD  2024-04-09  09:51AM   \n",
       "..         ...         ...      ...   \n",
       "562       AMZN  2024-04-08  07:03PM   \n",
       "563       AMZN  2024-04-07  06:46PM   \n",
       "564       AMZN  2024-04-06  10:00AM   \n",
       "565       AMZN  2024-04-05  07:22PM   \n",
       "566       AMZN  2024-04-04  10:11PM   \n",
       "\n",
       "                                         News Headline Sentiment  \n",
       "0    Tesla settles lawsuit in fatal crash where dri...   Neutral  \n",
       "1    Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral  \n",
       "2    Tesla wants Apple's help proving a driver was ...   Neutral  \n",
       "3    Wall Street Analysts Just Trimmed Price Target...   Neutral  \n",
       "4                          How's AT&T Handling Things?   Neutral  \n",
       "..                                                 ...       ...  \n",
       "562  Analyst unveils new Amazon price target as sto...   Neutral  \n",
       "563     Here Are My 3 Top Tech Stocks to Buy Right Now   Neutral  \n",
       "564     Best Stock to Buy Right Now: Amazon vs. Disney  Positive  \n",
       "565  Amazon continues construction on Puget Sound t...   Neutral  \n",
       "566                 20 Most Buddhist Countries in Asia   Neutral  \n",
       "\n",
       "[567 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped = df_news.groupby(['Date', 'Stock Name','Sentiment'])['News Headline'].apply(list).reset_index()\n",
    "#\n",
    "## Merge the grouped DataFrame with the original DataFrame\n",
    "#merged_df = pd.merge(df_news, grouped, on=['Date', 'Stock Name','Sentiment'], suffixes=(',', '_grouped'))\n",
    "#\n",
    "#merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.drop(columns=['Time','News Headline,'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df.head(20).sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime type\n",
    "#merged_df['Date'] =  pd.to_datetime(merged_df['Date']).dt.date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Neutral     326\n",
       "Positive    168\n",
       "Negative     73\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preproessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing steps completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tokenization\n",
    "# Tokenize the text\n",
    "\n",
    "df_news['Tokenized_Text'] = df_news['News Headline'].apply(word_tokenize)\n",
    "\n",
    "# Stop-word removal\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df_news['Tokenized_Text'] = df_news['Tokenized_Text'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
    "\n",
    "# Stemming\n",
    "# Perform stemming\n",
    "stemmer = PorterStemmer()\n",
    "df_news['Stemmed_Text'] = df_news['Tokenized_Text'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "# Lemmatization\n",
    "# Perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df_news['Lemmatized_Text'] = df_news['Tokenized_Text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Lowercasing\n",
    "# Convert text to lowercase\n",
    "\n",
    "df_news['Lowercased_Text'] = df_news['News Headline'].str.lower()\n",
    "\n",
    "print('Text preprocessing steps completed successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "      <th>Lowercased_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>10:03AM</td>\n",
       "      <td>Tesla settles lawsuit in fatal crash where dri...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tesla, settles, lawsuit, fatal, crash, driver...</td>\n",
       "      <td>[tesla, settl, lawsuit, fatal, crash, driver, ...</td>\n",
       "      <td>[Tesla, settle, lawsuit, fatal, crash, driver,...</td>\n",
       "      <td>tesla settles lawsuit in fatal crash where dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tesla, Agrees, Settle, Lawsuit, Autopilots, I...</td>\n",
       "      <td>[tesla, agre, settl, lawsuit, autopilot, invol...</td>\n",
       "      <td>[Tesla, Agrees, Settle, Lawsuit, Autopilots, I...</td>\n",
       "      <td>tesla agrees to settle lawsuit over autopilots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>10:08PM</td>\n",
       "      <td>Tesla wants Apple's help proving a driver was ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tesla, wants, Apple, 's, help, proving, drive...</td>\n",
       "      <td>[tesla, want, appl, 's, help, prove, driver, p...</td>\n",
       "      <td>[Tesla, want, Apple, 's, help, proving, driver...</td>\n",
       "      <td>tesla wants apple's help proving a driver was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>08:42PM</td>\n",
       "      <td>Wall Street Analysts Just Trimmed Price Target...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Wall, Street, Analysts, Trimmed, Price, Targe...</td>\n",
       "      <td>[wall, street, analyst, trim, price, target, 1...</td>\n",
       "      <td>[Wall, Street, Analysts, Trimmed, Price, Targe...</td>\n",
       "      <td>wall street analysts just trimmed price target...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>09:51AM</td>\n",
       "      <td>How's AT&amp;T Handling Things?</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>['s, &amp;, Handling, Things, ?]</td>\n",
       "      <td>['s, &amp;, handl, thing, ?]</td>\n",
       "      <td>['s, &amp;, Handling, Things, ?]</td>\n",
       "      <td>how's at&amp;t handling things?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name        Date     Time  \\\n",
       "0       TSLA  2024-04-09  10:03AM   \n",
       "1       TSLA  2024-04-08  10:46PM   \n",
       "2       TSLA  2024-04-07  10:08PM   \n",
       "3       TSLA  2024-04-06  08:42PM   \n",
       "4        AMD  2024-04-09  09:51AM   \n",
       "\n",
       "                                       News Headline Sentiment  \\\n",
       "0  Tesla settles lawsuit in fatal crash where dri...   Neutral   \n",
       "1  Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral   \n",
       "2  Tesla wants Apple's help proving a driver was ...   Neutral   \n",
       "3  Wall Street Analysts Just Trimmed Price Target...   Neutral   \n",
       "4                        How's AT&T Handling Things?   Neutral   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [Tesla, settles, lawsuit, fatal, crash, driver...   \n",
       "1  [Tesla, Agrees, Settle, Lawsuit, Autopilots, I...   \n",
       "2  [Tesla, wants, Apple, 's, help, proving, drive...   \n",
       "3  [Wall, Street, Analysts, Trimmed, Price, Targe...   \n",
       "4                       ['s, &, Handling, Things, ?]   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  [tesla, settl, lawsuit, fatal, crash, driver, ...   \n",
       "1  [tesla, agre, settl, lawsuit, autopilot, invol...   \n",
       "2  [tesla, want, appl, 's, help, prove, driver, p...   \n",
       "3  [wall, street, analyst, trim, price, target, 1...   \n",
       "4                           ['s, &, handl, thing, ?]   \n",
       "\n",
       "                                     Lemmatized_Text  \\\n",
       "0  [Tesla, settle, lawsuit, fatal, crash, driver,...   \n",
       "1  [Tesla, Agrees, Settle, Lawsuit, Autopilots, I...   \n",
       "2  [Tesla, want, Apple, 's, help, proving, driver...   \n",
       "3  [Wall, Street, Analysts, Trimmed, Price, Targe...   \n",
       "4                       ['s, &, Handling, Things, ?]   \n",
       "\n",
       "                                     Lowercased_Text  \n",
       "0  tesla settles lawsuit in fatal crash where dri...  \n",
       "1  tesla agrees to settle lawsuit over autopilots...  \n",
       "2  tesla wants apple's help proving a driver was ...  \n",
       "3  wall street analysts just trimmed price target...  \n",
       "4                        how's at&t handling things?  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>061</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youngest</th>\n",
       "      <th>zdge</th>\n",
       "      <th>zedge</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  061  10  100  100m  10x  11  11th  12  13  ...  year  years  yield  \\\n",
       "0    0    0   0    0     0    0   0     0   0   0  ...     0      0      0   \n",
       "1    0    0   0    0     0    0   0     0   0   0  ...     0      0      0   \n",
       "2    0    0   0    0     0    0   0     0   0   0  ...     0      0      0   \n",
       "3    0    0   1    0     0    0   0     0   0   0  ...     0      0      0   \n",
       "4    0    0   0    0     0    0   0     0   0   0  ...     0      0      0   \n",
       "\n",
       "   york  youll  youngest  zdge  zedge  zeus  zoomed  \n",
       "0     0      0         0     0      0     0       0  \n",
       "1     0      0         0     0      0     0       0  \n",
       "2     0      0         0     0      0     0       0  \n",
       "3     0      0         0     0      0     0       0  \n",
       "4     0      0         0     0      0     0       0  \n",
       "\n",
       "[5 rows x 1479 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # type: ignore\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "bow_features = count_vectorizer.fit_transform(df_news['Lowercased_Text'])\n",
    "bow_features_df = pd.DataFrame(bow_features.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "bow_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are so many columns, it is unlikely we will be able to use this as an analysis. Instead, we could have a look at words that appear frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>...</th>\n",
       "      <th>vale</th>\n",
       "      <th>vs</th>\n",
       "      <th>walgreens</th>\n",
       "      <th>wall</th>\n",
       "      <th>watch</th>\n",
       "      <th>wba</th>\n",
       "      <th>webcast</th>\n",
       "      <th>week</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  10  11  12  13  14  15  20  2022  2023  ...  vale  vs  walgreens  \\\n",
       "0      0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "1      0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "2      0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "3      0   1   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "4      0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "..   ...  ..  ..  ..  ..  ..  ..  ..   ...   ...  ...   ...  ..        ...   \n",
       "562    0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "563    0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "564    0   0   0   0   0   0   0   0     0     0  ...     0   1          0   \n",
       "565    0   0   0   0   0   0   0   0     0     0  ...     0   0          0   \n",
       "566    0   0   0   0   0   0   0   1     0     0  ...     0   0          0   \n",
       "\n",
       "     wall  watch  wba  webcast  week  world  year  \n",
       "0       0      0    0        0     0      0     0  \n",
       "1       0      0    0        0     0      0     0  \n",
       "2       0      0    0        0     0      0     0  \n",
       "3       1      0    0        0     0      0     0  \n",
       "4       0      0    0        0     0      0     0  \n",
       "..    ...    ...  ...      ...   ...    ...   ...  \n",
       "562     0      0    0        0     0      0     0  \n",
       "563     0      0    0        0     0      0     0  \n",
       "564     0      0    0        0     0      0     0  \n",
       "565     0      0    0        0     0      0     0  \n",
       "566     0      0    0        0     0      0     0  \n",
       "\n",
       "[567 rows x 145 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a mask so we only get the terms that have a frequency greater than 5 \n",
    "bow_frequent_words = list(bow_features_df.sum()[bow_features_df.sum() > 5].index)\n",
    "\n",
    "bow_features_df[bow_frequent_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This approach causes a significant dimensionality problem - the more documents have the larger the vocabulary, and the longer the vectors.\n",
    "* Additionally, the vectors would also contain many 0s, thereby resulting in a huge sparse feature matrix.\n",
    "* If the model comes across a new word it has not seen yet it will probably end up ignoring this word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>061</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youngest</th>\n",
       "      <th>zdge</th>\n",
       "      <th>zedge</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.308234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows Ã— 1479 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  061        10  100  100m  10x   11  11th   12   13  ...  year  \\\n",
       "0    0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "1    0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "2    0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "3    0.0  0.0  0.308234  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "4    0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "..   ...  ...       ...  ...   ...  ...  ...   ...  ...  ...  ...   ...   \n",
       "562  0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "563  0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "564  0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "565  0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "566  0.0  0.0  0.000000  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "     years  yield  york  youll  youngest  zdge  zedge  zeus  zoomed  \n",
       "0      0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "1      0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "2      0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "3      0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "4      0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "..     ...    ...   ...    ...       ...   ...    ...   ...     ...  \n",
       "562    0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "563    0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "564    0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "565    0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "566    0.0    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "\n",
       "[567 rows x 1479 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df_news['Lowercased_Text'])\n",
    "tfidf_features_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As above with the Bag of Words, the data is high dimensional and any useful analysis would require selecting the columns with the highest TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "      <th>Lowercased_Text</th>\n",
       "      <th>BERT_Embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>08:32AM</td>\n",
       "      <td>Elon Musk is trying highlight the value that r...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Elon, Musk, trying, highlight, value, robotax...</td>\n",
       "      <td>[elon, musk, tri, highlight, valu, robotaxi, c...</td>\n",
       "      <td>[Elon, Musk, trying, highlight, value, robotax...</td>\n",
       "      <td>elon musk is trying highlight the value that r...</td>\n",
       "      <td>[[[tensor(-0.4156, grad_fn=&lt;UnbindBackward0&gt;),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tesla, Agrees, Settle, Lawsuit, Autopilots, I...</td>\n",
       "      <td>[tesla, agre, settl, lawsuit, autopilot, invol...</td>\n",
       "      <td>[Tesla, Agrees, Settle, Lawsuit, Autopilots, I...</td>\n",
       "      <td>tesla agrees to settle lawsuit over autopilots...</td>\n",
       "      <td>[[[tensor(-0.4517, grad_fn=&lt;UnbindBackward0&gt;),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>10:08PM</td>\n",
       "      <td>Tesla wants Apple's help proving a driver was ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tesla, wants, Apple, 's, help, proving, drive...</td>\n",
       "      <td>[tesla, want, appl, 's, help, prove, driver, p...</td>\n",
       "      <td>[Tesla, want, Apple, 's, help, proving, driver...</td>\n",
       "      <td>tesla wants apple's help proving a driver was ...</td>\n",
       "      <td>[[[tensor(-0.5963, grad_fn=&lt;UnbindBackward0&gt;),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>08:42PM</td>\n",
       "      <td>Wall Street Analysts Just Trimmed Price Target...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Wall, Street, Analysts, Trimmed, Price, Targe...</td>\n",
       "      <td>[wall, street, analyst, trim, price, target, 1...</td>\n",
       "      <td>[Wall, Street, Analysts, Trimmed, Price, Targe...</td>\n",
       "      <td>wall street analysts just trimmed price target...</td>\n",
       "      <td>[[[tensor(-0.2533, grad_fn=&lt;UnbindBackward0&gt;),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>07:15AM</td>\n",
       "      <td>3 Stocks That Can Help You Get Richer in 2024</td>\n",
       "      <td>Positive</td>\n",
       "      <td>[3, Stocks, Help, Get, Richer, 2024]</td>\n",
       "      <td>[3, stock, help, get, richer, 2024]</td>\n",
       "      <td>[3, Stocks, Help, Get, Richer, 2024]</td>\n",
       "      <td>3 stocks that can help you get richer in 2024</td>\n",
       "      <td>[[[tensor(-0.2304, grad_fn=&lt;UnbindBackward0&gt;),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name        Date     Time  \\\n",
       "0       TSLA  2024-04-09  08:32AM   \n",
       "1       TSLA  2024-04-08  10:46PM   \n",
       "2       TSLA  2024-04-07  10:08PM   \n",
       "3       TSLA  2024-04-06  08:42PM   \n",
       "4        AMD  2024-04-09  07:15AM   \n",
       "\n",
       "                                       News Headline Sentiment  \\\n",
       "0  Elon Musk is trying highlight the value that r...   Neutral   \n",
       "1  Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral   \n",
       "2  Tesla wants Apple's help proving a driver was ...   Neutral   \n",
       "3  Wall Street Analysts Just Trimmed Price Target...   Neutral   \n",
       "4      3 Stocks That Can Help You Get Richer in 2024  Positive   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0  [Elon, Musk, trying, highlight, value, robotax...   \n",
       "1  [Tesla, Agrees, Settle, Lawsuit, Autopilots, I...   \n",
       "2  [Tesla, wants, Apple, 's, help, proving, drive...   \n",
       "3  [Wall, Street, Analysts, Trimmed, Price, Targe...   \n",
       "4               [3, Stocks, Help, Get, Richer, 2024]   \n",
       "\n",
       "                                        Stemmed_Text  \\\n",
       "0  [elon, musk, tri, highlight, valu, robotaxi, c...   \n",
       "1  [tesla, agre, settl, lawsuit, autopilot, invol...   \n",
       "2  [tesla, want, appl, 's, help, prove, driver, p...   \n",
       "3  [wall, street, analyst, trim, price, target, 1...   \n",
       "4                [3, stock, help, get, richer, 2024]   \n",
       "\n",
       "                                     Lemmatized_Text  \\\n",
       "0  [Elon, Musk, trying, highlight, value, robotax...   \n",
       "1  [Tesla, Agrees, Settle, Lawsuit, Autopilots, I...   \n",
       "2  [Tesla, want, Apple, 's, help, proving, driver...   \n",
       "3  [Wall, Street, Analysts, Trimmed, Price, Targe...   \n",
       "4               [3, Stocks, Help, Get, Richer, 2024]   \n",
       "\n",
       "                                     Lowercased_Text  \\\n",
       "0  elon musk is trying highlight the value that r...   \n",
       "1  tesla agrees to settle lawsuit over autopilots...   \n",
       "2  tesla wants apple's help proving a driver was ...   \n",
       "3  wall street analysts just trimmed price target...   \n",
       "4      3 stocks that can help you get richer in 2024   \n",
       "\n",
       "                                     BERT_Embeddings  \n",
       "0  [[[tensor(-0.4156, grad_fn=<UnbindBackward0>),...  \n",
       "1  [[[tensor(-0.4517, grad_fn=<UnbindBackward0>),...  \n",
       "2  [[[tensor(-0.5963, grad_fn=<UnbindBackward0>),...  \n",
       "3  [[[tensor(-0.2533, grad_fn=<UnbindBackward0>),...  \n",
       "4  [[[tensor(-0.2304, grad_fn=<UnbindBackward0>),...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "df_news['BERT_Embeddings'] = df_news['Lowercased_Text'].apply(lambda x: model(**tokenizer(x, return_tensors='pt')).last_hidden_state)\n",
    "\n",
    "df_news.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
