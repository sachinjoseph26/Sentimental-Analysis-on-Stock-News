{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Collection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Pull News about each Stock*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Get today's date\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Define the start and end dates\n",
    "#start_date = datetime(2021, 1, 1)\n",
    "#end_date = datetime(2024, 4, 10)\n",
    "\n",
    "with open('news_data.csv', 'w', newline='') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    # Write the header row\n",
    "    csv_writer.writerow(['Stock Name','Date','Time','News Headline'])\n",
    "\n",
    "stocks = ['TSLA','AMD','NVDA','MU','PLTR','NIO','AAPL','MARA','WBA','CLSK','F','CCL','SOFI','T','BAC','GOOGL','VALE','GOLD','INTC','AMZN']\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "\n",
    "for stock in stocks:\n",
    "    final_url = finviz_url + stock\n",
    "    request = Request(url=final_url, headers={'user-agent': 'app'}) \n",
    "    response = urlopen(request)    \n",
    "    html = BeautifulSoup(response, features=\"lxml\")\n",
    "    news_table = html.find('table',id='news-table')\n",
    "    news_table_row = news_table.find_all('tr')\n",
    "    for news in news_table_row:\n",
    "        news_headline = news.a.get_text() \n",
    "        date_scrape = news.td.text.split()\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            # Replace \"Today\" with today's date\n",
    "            news_date = today_date\n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "            # Replace \"Today\" with today's date\n",
    "            if date.lower() == \"today\":\n",
    "                news_date = today_date\n",
    "            else:\n",
    "                # Convert the scraped date to a datetime object\n",
    "                news_date = datetime.strptime(date, '%b-%d-%y').date()  # Extracting only the date portion\n",
    "            # Check if the news date falls within the specified range\n",
    "            \n",
    "            with open('news_data.csv', 'a', newline='') as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([stock, news_date, time, news_headline])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Annotate sentiments of news headlines with a pretrained model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Cathie Wood Is Dumping Nvidia and Buying Tesla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst revises Tesla stock price target after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>11:29PM</td>\n",
       "      <td>Google unveils first Arm-based data center CPU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>08:30PM</td>\n",
       "      <td>Better Artificial Intelligence (AI) Stock: Qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>05:25PM</td>\n",
       "      <td>Sephora, Ulta, and e.l.f. among the top beauty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst unveils new Amazon price target as sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>06:46PM</td>\n",
       "      <td>Here Are My 3 Top Tech Stocks to Buy Right Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Best Stock to Buy Right Now: Amazon vs. Disney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>07:22PM</td>\n",
       "      <td>Amazon continues construction on Puget Sound t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name        Date     Time  \\\n",
       "0         TSLA  2024-04-10  10:00AM   \n",
       "1         TSLA  2024-04-09  07:03PM   \n",
       "2         TSLA  2024-04-08  10:46PM   \n",
       "3          AMD  2024-04-09  11:29PM   \n",
       "4          AMD  2024-04-08  08:30PM   \n",
       "..         ...         ...      ...   \n",
       "555       AMZN  2024-04-09  05:25PM   \n",
       "556       AMZN  2024-04-08  07:03PM   \n",
       "557       AMZN  2024-04-07  06:46PM   \n",
       "558       AMZN  2024-04-06  10:00AM   \n",
       "559       AMZN  2024-04-05  07:22PM   \n",
       "\n",
       "                                         News Headline  \n",
       "0    Cathie Wood Is Dumping Nvidia and Buying Tesla...  \n",
       "1    Analyst revises Tesla stock price target after...  \n",
       "2    Tesla Agrees to Settle Lawsuit Over Autopilots...  \n",
       "3    Google unveils first Arm-based data center CPU...  \n",
       "4    Better Artificial Intelligence (AI) Stock: Qua...  \n",
       "..                                                 ...  \n",
       "555  Sephora, Ulta, and e.l.f. among the top beauty...  \n",
       "556  Analyst unveils new Amazon price target as sto...  \n",
       "557     Here Are My 3 Top Tech Stocks to Buy Right Now  \n",
       "558     Best Stock to Buy Right Now: Amazon vs. Disney  \n",
       "559  Amazon continues construction on Puget Sound t...  \n",
       "\n",
       "[560 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv('news_data.csv',encoding='ISO-8859-1')\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "nlp = pipeline('sentiment-analysis', model=finbert, tokenizer=tokenizer)\n",
    "\n",
    "df_news['Sentiment'] = df_news['News Headline'].apply(lambda x: nlp(x)[0]['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Cathie Wood Is Dumping Nvidia and Buying Tesla...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst revises Tesla stock price target after...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>11:29PM</td>\n",
       "      <td>Google unveils first Arm-based data center CPU...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>08:30PM</td>\n",
       "      <td>Better Artificial Intelligence (AI) Stock: Qua...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>05:25PM</td>\n",
       "      <td>Sephora, Ulta, and e.l.f. among the top beauty...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst unveils new Amazon price target as sto...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-07</td>\n",
       "      <td>06:46PM</td>\n",
       "      <td>Here Are My 3 Top Tech Stocks to Buy Right Now</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-06</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Best Stock to Buy Right Now: Amazon vs. Disney</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2024-04-05</td>\n",
       "      <td>07:22PM</td>\n",
       "      <td>Amazon continues construction on Puget Sound t...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Stock Name        Date     Time  \\\n",
       "0         TSLA  2024-04-10  10:00AM   \n",
       "1         TSLA  2024-04-09  07:03PM   \n",
       "2         TSLA  2024-04-08  10:46PM   \n",
       "3          AMD  2024-04-09  11:29PM   \n",
       "4          AMD  2024-04-08  08:30PM   \n",
       "..         ...         ...      ...   \n",
       "555       AMZN  2024-04-09  05:25PM   \n",
       "556       AMZN  2024-04-08  07:03PM   \n",
       "557       AMZN  2024-04-07  06:46PM   \n",
       "558       AMZN  2024-04-06  10:00AM   \n",
       "559       AMZN  2024-04-05  07:22PM   \n",
       "\n",
       "                                         News Headline Sentiment  \n",
       "0    Cathie Wood Is Dumping Nvidia and Buying Tesla...  Negative  \n",
       "1    Analyst revises Tesla stock price target after...   Neutral  \n",
       "2    Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral  \n",
       "3    Google unveils first Arm-based data center CPU...  Negative  \n",
       "4    Better Artificial Intelligence (AI) Stock: Qua...  Positive  \n",
       "..                                                 ...       ...  \n",
       "555  Sephora, Ulta, and e.l.f. among the top beauty...   Neutral  \n",
       "556  Analyst unveils new Amazon price target as sto...   Neutral  \n",
       "557     Here Are My 3 Top Tech Stocks to Buy Right Now   Neutral  \n",
       "558     Best Stock to Buy Right Now: Amazon vs. Disney  Positive  \n",
       "559  Amazon continues construction on Puget Sound t...   Neutral  \n",
       "\n",
       "[560 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "Neutral     317\n",
       "Positive    168\n",
       "Negative     75\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preproessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Handle emojis and specific characters\n",
    "    text = re.sub(r'[:;=x][\\-o\\*]?[\\)\\(\\[\\]dpo\\@\\>\\<\\}3]', '', text)  # Removes typical emojis/smiley faces\n",
    "    # Handle hashtags and mentions\n",
    "    text = re.sub(r'#[\\w-]+', 'hashtag', text)  # Replace hashtags\n",
    "    text = re.sub(r'@[\\w-]+', 'mention', text)  # Replace mentions\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    # Rejoin tokens\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing\n",
    "df_news['processed_text'] = df_news['News Headline'].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>10:00AM</td>\n",
       "      <td>Cathie Wood Is Dumping Nvidia and Buying Tesla...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>cathie wood dumping nvidia buying tesla : maki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst revises Tesla stock price target after...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>analyst revise tesla stock price target robota...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tesla agrees settle lawsuit autopilot involvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>11:29PM</td>\n",
       "      <td>Google unveils first Arm-based data center CPU...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>google unveils first arm-based data center cpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>08:30PM</td>\n",
       "      <td>Better Artificial Intelligence (AI) Stock: Qua...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>better artificial intelligence ( ai ) stock : ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name        Date     Time  \\\n",
       "0       TSLA  2024-04-10  10:00AM   \n",
       "1       TSLA  2024-04-09  07:03PM   \n",
       "2       TSLA  2024-04-08  10:46PM   \n",
       "3        AMD  2024-04-09  11:29PM   \n",
       "4        AMD  2024-04-08  08:30PM   \n",
       "\n",
       "                                       News Headline Sentiment  \\\n",
       "0  Cathie Wood Is Dumping Nvidia and Buying Tesla...  Negative   \n",
       "1  Analyst revises Tesla stock price target after...   Neutral   \n",
       "2  Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral   \n",
       "3  Google unveils first Arm-based data center CPU...  Negative   \n",
       "4  Better Artificial Intelligence (AI) Stock: Qua...  Positive   \n",
       "\n",
       "                                      processed_text  \n",
       "0  cathie wood dumping nvidia buying tesla : maki...  \n",
       "1  analyst revise tesla stock price target robota...  \n",
       "2  tesla agrees settle lawsuit autopilot involvem...  \n",
       "3  google unveils first arm-based data center cpu...  \n",
       "4  better artificial intelligence ( ai ) stock : ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>061</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youngest</th>\n",
       "      <th>zdge</th>\n",
       "      <th>zedge</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  061  10  100  100m  10x  11  11th  12  13  ...  yahoo  year  yield  \\\n",
       "0    0    0   0    0     0    0   0     0   0   0  ...      0     0      0   \n",
       "1    0    0   0    0     0    0   0     0   0   0  ...      0     0      0   \n",
       "2    0    0   0    0     0    0   0     0   0   0  ...      0     0      0   \n",
       "3    0    0   0    0     0    0   0     0   0   0  ...      0     0      0   \n",
       "4    0    0   0    0     0    0   0     0   0   0  ...      0     0      0   \n",
       "\n",
       "   york  youll  youngest  zdge  zedge  zeus  zoomed  \n",
       "0     0      0         0     0      0     0       0  \n",
       "1     0      0         0     0      0     0       0  \n",
       "2     0      0         0     0      0     0       0  \n",
       "3     0      0         0     0      0     0       0  \n",
       "4     0      0         0     0      0     0       0  \n",
       "\n",
       "[5 rows x 1332 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # type: ignore\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "X_bow = count_vectorizer.fit_transform(df_news['processed_text'])\n",
    "bow_features_df = pd.DataFrame(X_bow.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "\n",
    "bow_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>061</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>100m</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>youngest</th>\n",
       "      <th>zdge</th>\n",
       "      <th>zedge</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 1332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     000  061   10  100  100m  10x   11  11th   12   13  ...  yahoo  year  \\\n",
       "0    0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1    0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2    0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3    0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4    0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "..   ...  ...  ...  ...   ...  ...  ...   ...  ...  ...  ...    ...   ...   \n",
       "555  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "556  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "557  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "558  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "559  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "     yield  york  youll  youngest  zdge  zedge  zeus  zoomed  \n",
       "0      0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "1      0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "2      0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "3      0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "4      0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "..     ...   ...    ...       ...   ...    ...   ...     ...  \n",
       "555    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "556    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "557    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "558    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "559    0.0   0.0    0.0       0.0   0.0    0.0   0.0     0.0  \n",
       "\n",
       "[560 rows x 1332 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(df_news['processed_text'])\n",
    "tfidf_features_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "tfidf_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>BERT_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-10</td>\n",
       "      <td>08:31AM</td>\n",
       "      <td>Tesla strike in Sweden continues, union says, ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tesla strike sweden continues , union say , co...</td>\n",
       "      <td>-0.360706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>07:03PM</td>\n",
       "      <td>Analyst revises Tesla stock price target after...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>analyst revise tesla stock price target robota...</td>\n",
       "      <td>-0.192663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>10:46PM</td>\n",
       "      <td>Tesla Agrees to Settle Lawsuit Over Autopilots...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>tesla agrees settle lawsuit autopilot involvem...</td>\n",
       "      <td>-0.460014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>11:29PM</td>\n",
       "      <td>Google unveils first Arm-based data center CPU...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>google unveils first arm-based data center cpu...</td>\n",
       "      <td>-0.635717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>2024-04-08</td>\n",
       "      <td>08:30PM</td>\n",
       "      <td>Better Artificial Intelligence (AI) Stock: Qua...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>better artificial intelligence ( ai ) stock : ...</td>\n",
       "      <td>-0.637123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name        Date     Time  \\\n",
       "0       TSLA  2024-04-10  08:31AM   \n",
       "1       TSLA  2024-04-09  07:03PM   \n",
       "2       TSLA  2024-04-08  10:46PM   \n",
       "3        AMD  2024-04-09  11:29PM   \n",
       "4        AMD  2024-04-08  08:30PM   \n",
       "\n",
       "                                       News Headline Sentiment  \\\n",
       "0  Tesla strike in Sweden continues, union says, ...   Neutral   \n",
       "1  Analyst revises Tesla stock price target after...   Neutral   \n",
       "2  Tesla Agrees to Settle Lawsuit Over Autopilots...   Neutral   \n",
       "3  Google unveils first Arm-based data center CPU...  Negative   \n",
       "4  Better Artificial Intelligence (AI) Stock: Qua...  Positive   \n",
       "\n",
       "                                      processed_text  BERT_embedding  \n",
       "0  tesla strike sweden continues , union say , co...       -0.360706  \n",
       "1  analyst revise tesla stock price target robota...       -0.192663  \n",
       "2  tesla agrees settle lawsuit autopilot involvem...       -0.460014  \n",
       "3  google unveils first arm-based data center cpu...       -0.635717  \n",
       "4  better artificial intelligence ( ai ) stock : ...       -0.637123  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Move model to the device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def batch_encode(texts, tokenizer, max_length=512):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        max_length=max_length,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "def get_bert_embeddings(texts, tokenizer, model, batch_size=16):\n",
    "    # Split texts into batches\n",
    "    batches = [texts[i:i + batch_size] for i in range(0, len(texts), batch_size)]\n",
    "    embeddings = []\n",
    "    \n",
    "    for batch in batches:\n",
    "        encoded_inputs = batch_encode(batch, tokenizer)\n",
    "        input_ids = encoded_inputs['input_ids'].to(device)\n",
    "        attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the embeddings for the `[CLS]` token (first token) representing the whole sequence\n",
    "        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.append(cls_embeddings)\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    return np.concatenate(embeddings)\n",
    "\n",
    "# Example usage\n",
    "texts = df_news['processed_text'].tolist()\n",
    "embeddings = get_bert_embeddings(texts, tokenizer, model)\n",
    "\n",
    "# Since embeddings is a numpy array, you can decide how to add it to your DataFrame. For instance:\n",
    "# Assuming you want to keep just the first embedding dimension as an example\n",
    "df_news['BERT_embedding'] = embeddings[:, 0].tolist()\n",
    "\n",
    "# Display the DataFrame to verify\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are taking BOW embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Selection and Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `df_news['sentiment']` is your target variable and is binary (0 for negative, 1 for positive sentiment)\n",
    "# Convert sentiment to numeric if it's not already\n",
    "\n",
    "df_news['sentiment_numeric'] = df_news['Sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive': 2})\n",
    "\n",
    "y = df_news['sentiment_numeric'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8995535714285714\n",
      "Testing Accuracy: 0.4732142857142857\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.18      0.14        11\n",
      "           1       0.73      0.48      0.58        73\n",
      "           2       0.35      0.57      0.43        28\n",
      "\n",
      "    accuracy                           0.47       112\n",
      "   macro avg       0.40      0.41      0.38       112\n",
      "weighted avg       0.57      0.47      0.50       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train with BoW features\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Deployment and Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "# Function to classify and display the sentiment\n",
    "def classify_headline():\n",
    "    headline = entry.get()\n",
    "    processed = preprocess_text(headline)\n",
    "    vectorized = count_vectorizer.transform([processed])\n",
    "    prediction = model.predict(vectorized)\n",
    "    result_label.config(text = f\"Sentiment: {'Positive' if prediction == 2 else 'Neutral' if prediction == 1 else 'Negative'}\")\n",
    "\n",
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Stock News Sentiment Analysis\")\n",
    "\n",
    "frame = ttk.Frame(root, padding=\"30\")\n",
    "frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))\n",
    "\n",
    "entry = ttk.Entry(frame, width=50)\n",
    "entry.grid(row=0, column=0, sticky=(tk.W, tk.E))\n",
    "\n",
    "button = ttk.Button(frame, text=\"Classify\", command=classify_headline)\n",
    "button.grid(row=1, column=0, sticky=tk.W, pady=10)\n",
    "\n",
    "result_label = ttk.Label(frame, text=\"Sentiment: \")\n",
    "result_label.grid(row=2, column=0, sticky=tk.W)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cpu",
   "language": "python",
   "name": "pytorch_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
